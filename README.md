
# ðŸ’» Tech Stack and Tools

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![R](https://img.shields.io/badge/r-%23276DC3.svg?style=for-the-badge&logo=r&logoColor=white)
![Java](https://img.shields.io/badge/java-%23ED8B00.svg?style=for-the-badge&logo=openjdk&logoColor=white)

![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=flat&logo=Keras&logoColor=white)

![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![torchvision](https://img.shields.io/badge/torchvision-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
![torchaudio](https://img.shields.io/badge/torchaudio-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
![torch.nn](https://img.shields.io/badge/torch.nn-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
![torch.optim](https://img.shields.io/badge/torch.optim-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
![torch.autograd](https://img.shields.io/badge/torch.autograd-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
![torch.cuda](https://img.shields.io/badge/torch.cuda-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)
![torch.onnx](https://img.shields.io/badge/torch.onnx-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)

![LangChain](https://img.shields.io/badge/LangChain-%231C3C3C?style=for-the-badge&logo=langchain&logoColor=white)
![LangGraph](https://img.shields.io/badge/LangGraph-%231C3C3C?style=flat&logo=langgraph&logoColor=white&scale=0.75)   

![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0097A7?style=for-the-badge&logo=google&logoColor=white)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white)
![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white)
![Librosa](https://img.shields.io/badge/Librosa-orange?style=for-the-badge)
![soundfile](https://img.shields.io/badge/soundfile-green?style=for-the-badge&logoColor=white)

![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white)
![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![Hugging Face](https://img.shields.io/badge/ðŸ¤—_Hugging_Face-FFD21E?style=for-the-badge)

![Jupyter](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)
![Visual Studio Code](https://img.shields.io/badge/Visual%20Studio%20Code-0078d7.svg?style=for-the-badge&logo=visual-studio-code&logoColor=white)
![Google Colab](https://img.shields.io/badge/Google%20Colab-F9AB00.svg?style=for-the-badge&logo=googlecolab&logoColor=white)

# :bookmark_tabs: Research Stack and References
ðŸ“„ [Implementation](https://github.com/HazCodesLots/AudioForgeryDetection/tree/main/FrontEnds/ConvNeXt) **A ConvNet for the 2020s (ConvNeXt)** - Liu et al., CVPR 2022 | [Paper](https://arxiv.org/abs/2201.03545)  
ðŸ“„ [Implementation](https://github.com/HazCodesLots/AudioForgeryDetection/tree/main/FrontEnds/ResNet) **Deep Residual Learning for Image Recognition** - He et al., CVPR 2016 | [Paper](https://arxiv.org/abs/1512.03385)  
ðŸ“„ [Implementation](https://github.com/HazCodesLots/AudioForgeryDetection/tree/main/FrontEnds/ResNet) **Res2Net: A New Multi-scale Backbone Architecture** - Gao et al., TPAMI 2021 | [Paper](https://arxiv.org/abs/1904.01169)    
ðŸ“„ [Implementation](https://github.com/HazCodesLots/Nueral-Image-Caption-Generator) **Show and Tell: A Neural Image Caption Generator** - Vinyals et al., CVPR 2015 | [Paper](https://arxiv.org/abs/1411.4555)  
ðŸ“„ [Implementation](https://github.com/HazCodesLots/Mutimodel-Agentic-Assistant/blob/main/ToolBox/DeepSeekOCR.py) **DeepSeek-OCR: Contexts Optical Compression** - Wei et al., arXiv 2025 | [Paper](https://arxiv.org/abs/2510.18234)  
ðŸ“„ [Implementation](https://github.com/HazCodesLots/MediaPipe-Posture-Detection) **MediaPipe: A Framework for Building Perception Pipelines** - Lugaresi et al., 2019 | [Paper](https://arxiv.org/abs/1906.08172)  
ðŸ“„ [Implementation](https://github.com/HazCodesLots/Mutimodel-Agentic-Assistant/blob/main/ToolBox/FAISS-RAG.ipynb) **Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks** - Lewis et al., NeurIPS 2020 | [Paper](https://arxiv.org/abs/2005.11401)  
ðŸ“„ [Implementation](https://github.com/HazCodesLots/AudioForgeryDetection) **Focal Loss for Dense Object Detection**  - Lin et al., ICCV 2017 | [Paper](https://arxiv.org/abs/1708.02002)  
ðŸ“„ [Implementation](https://github.com/HazCodesLots/AudioForgeryDetection/tree/main/FrontEnds/AASIST) **AASIST: Audio Anti-Spoofing using Integrated Spectro-Temporal Graph Attention Networks**
<br>- Jung et al., ICASSP 2022 | [Paper](https://arxiv.org/abs/2110.01200)    
